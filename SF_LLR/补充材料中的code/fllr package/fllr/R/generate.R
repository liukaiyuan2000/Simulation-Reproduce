#' Data simulation
#'
#' Simulates a random sample from models (M1)-(M3) from Ferraty and Nagy (2020).
#'
#' @param nlearn    number of learning functions
#' @param ntest     number of testing functions
#' @param Jmodel    effective dimension of the regressors, number of basis
#' functions on which the responses truly depend
#' @param nsr       noise-to-signal ration, a number between 0 and 1
#' @param aa        coefficient a in model \code{M3}, determining the linear
#' combination of the linear and the non-linear part of the regression
#' @param rho       parameter that drives the noise in the confounding part of
#' the regressors in models \code{M2} and \code{M3}, i.e. the part of the
#' regressors that corresponds to basis functions that do not contribute to the
#' modelling of the response
#' @param model     indicator of the model used, accepted are \code{"M1"},
#' \code{"M2"} or \code{"M3"}
#'
#' @return A list with the following components:
#' \itemize{
#' \item \code{LEARN} Matrix of dimension nlearn-times-101, one learning
#' function per row.
#' \item \code{PRED}  Matrix of new regressors of dimension npred-times-101, one
#' function per row.
#' \item \code{Responses} Vector of responses that correspond to the rows of
#' \code{LEARN}.
#' \item \code{oracle.Responses} True (unknown) responses generated by the model
#' that correspond to the rows of \code{PRED}.
#' \item \code{oracle.DERIV} True (unknown) functional derivatives generated
#' by the model that correspond to the rows of \code{PRED}.
#' \item \code{fDERIV = DERIV} The complete matrix of functional derivatives of
#' dimension (nlearn+npred)-times-101, first nlearn functions correspond to the
#' rows of \code{LEARN}, the remaining npred function to the rows of
#' \code{PRED}.
#' \item \code{fRegression} The complete vector of noiseless conditional
#' expectations in the model of length (nlearn+npred), first nlearn values
#' correspond to the rows of \code{LEARN}, the remaining npred values to the
#' rows of \code{PRED}.
#' \item \code{DERIV} True functional derivatives generated by the model.
#' Matrix of dimension nlearn-times-101, one row per a row of \code{LEARN}.
#' \item \code{BASIS} Matrix of the basis vectors into which the functional
#' regressors were decomposed.
#' }
#'
#' @author Stanislav Nagy, \email{nagy at karlin.mff.cuni.cz}
#'
#'	@references Ferraty, F., and Nagy, S. (2020).
#'	Scalar-on-function local linear regression and beyond.
#'	\emph{Under review}.
#'
#' @examples
#' dat = generate(100,200,4)
#' LEARN = dat$LEARN
#' PRED = dat$PRED
#' Responses = dat$Responses
#'
#' res = fllr(Responses, LEARN, PRED)
#'
#' plot(res$Predicted.responses~dat$oracle.Responses)
#'

generate = function(nlearn=100, ntest=500, Jmodel=4, nsr=.05, aa=1, rho = NULL,
                    model="M1"){
  # simulates a random sample in the study in the paper,
  # using the parameters provided
  # nlearn - learning sample size
  # ntest  - testing sample size
  # Jmodel - effective dimension of the dataset, Response depends only on Jmodel
  #          pricipal components of the data
  # nsr    - noise to signal ratio
  # aa     - parameter a tuning for non-linearity of the regression problem
  # model  - "M1" - J basis functions, only non-linear response
  #        - "M2" - 2*J basis functions, only non-linear response
  #        - "M3" - 2*J basis functions, linear and non-linear response

  gridsize = 101                           # grid size
  Grid = seq(0, 1, length = gridsize)      # grid of measurements
  sample.size = nlearn + ntest             # whole sample size
  if(model=="M1") BASIS = phif(Jmodel, Grid)
  if(model=="M2"|model=="M3") BASIS = phif(2 * Jmodel, Grid)
  # if model M2 and M3 compute 2*J Fourier basis elements
  bound = function(ratio){sqrt(ratio/(1 - ratio))}
  ################################
  # Simulate functional predictors
  ################################
  if(is.null(rho)) rho = nsr
  UNIF1 = matrix(runif(sample.size * Jmodel, min = -1, max = 1), nrow =
                   sample.size, ncol = Jmodel)
  b = bound(rho)
  UNIF2 = matrix(runif(sample.size * Jmodel, min = -b, max = b), nrow =
                   sample.size, ncol = Jmodel)
  if(model=="M1") PREDICTORS = UNIF1 %*% BASIS[1:Jmodel, ]
  if(model=="M2"|model=="M3") PREDICTORS = UNIF1 %*% BASIS[1:Jmodel, ] +
    UNIF2 %*% BASIS[-(1:Jmodel), ]
  ##############################################################################
  # Simulate linear part for regression and functional derivative
  ##############################################################################
  Beta = apply(BASIS[1:Jmodel, ], 2, sum)
  linear.part = (PREDICTORS %*% Beta - 0.5 * PREDICTORS[, c(1, gridsize)] %*%
                   Beta[c(1, gridsize)]) / (gridsize - 1)
  DERIV.LINEAR = matrix(rep(Beta, sample.size), nrow = sample.size, ncol =
                          gridsize, byrow = T)
  ##############################################################################
  # Simulate nonparametric part for regression and functional derivative
  ##############################################################################
  TRANSFORMED.REG = exp(- UNIF1^2)
  TRANSFORMED.DERIV = - 2 * UNIF1 * TRANSFORMED.REG
  np.part = apply(TRANSFORMED.REG, 1, sum)
  DERIV.NP = TRANSFORMED.DERIV %*% BASIS[1:Jmodel,]
  ##############################################################################
  # Compute the whole regression operator and functional derivaitve
  ##############################################################################
  if(model=="M1"|model=="M2"){
    Regression = np.part
    DERIV = DERIV.NP
  }
  if(model=="M3"){
    Regression = (1 - aa) * linear.part + aa * np.part
    DERIV = (1 - aa) * DERIV.LINEAR + aa * DERIV.NP
  }
  ##############################################################################
  # Simulate scalar responses (Responses) with given signal-to-signal ratio nsr
  ##############################################################################
  sigma = sqrt(nsr * var(Regression))
  error = rnorm(sample.size, sd = sigma)
  Responses.fullsample = Regression + error
  #####################################
  # Build learning sample
  #####################################
  LEARN = PREDICTORS[1:nlearn, ]
  PRED = PREDICTORS[-(1:nlearn), ]
  Responses = Responses.fullsample[1:nlearn]
  return(list(LEARN=LEARN, PRED = PRED, Responses = Responses,
              oracle.Responses = Regression[-(1:nlearn)],
              oracle.DERIV = DERIV[-(1:nlearn), ],
              fDERIV = DERIV,
              fRegression = Regression,
              DERIV = DERIV[(1:nlearn), ],
              BASIS = BASIS))
}
